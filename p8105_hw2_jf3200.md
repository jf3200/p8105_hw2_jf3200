Homework 2
================
Jessica Flynn

``` r
library(tidyverse)
```

    ## -- Attaching packages ---------------------------------------- tidyverse 1.3.0 --

    ## v ggplot2 3.3.2     v purrr   0.3.4
    ## v tibble  3.0.3     v dplyr   1.0.2
    ## v tidyr   1.1.2     v stringr 1.4.0
    ## v readr   1.3.1     v forcats 0.5.0

    ## -- Conflicts ------------------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate( 
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read in precipitation data for 2018 and 2017

``` r
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation", 
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation", 
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Combine annual precipitation

``` r
precip_df = 
  bind_rows(precip_2017, precip_2018)
```

Create month name

``` r
month_df = 
  tibble( 
    month = 1:12, 
    month_name = month.name
  )

precip_df = 
  left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, MD. As trash enters the harbor, the trashwheel
collects that trash and stores it in a dumpster. The dataset contains
information on year, month and trash collected. Some specific trash
types that are reported on include `cigarette_butts`, `chip_bags` and
`plastic_bottles`, among others. There are also some metrics regarding
the trash including `weight_tons` and `volume_cubic_yards`. There are a
total of 344 rows in the final dataset and a total of 14 columns. The
median number of sportsballs in a dumpster in 2017 was 8.

Additional data sheets include precipitation data by month. Here, we
looked specifically at the years 2017 and 2018. There are a total of 24
rows in the data for these two years. The columns in the dataset include
year, month, total, month\_name. The total precipitation in 2018 was
70.33 and the total in 2017 was 32.93.

## Problem 2

Read in NYC Transit Data

``` r
transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude,starts_with("route"),entry, vending, entrance_type, ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE)) %>% 
  mutate_at(vars(route8:route11),
            as.character) %>% 
  pivot_longer(route1:route11, 
               names_to = "route_name", 
               values_to = "route_number") %>% 
  drop_na(route_number)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

This dataset contains data related to the entrances and exits for each
subway station in NYC.

The cleaning steps thus far have included renaming the columns to be all
snake-case and lowercase using `janitor::clean_names()`. Next, I used
`select()`to retain the columns of interest and converted `entry`from a
character to a logical variable. These data were not in a tidy format.
Having route1- route11 each as columns indicates to us that this may not
be the tidiest way to present the data. In order to tidy these data, I
first converted all of the route variables to be of the same class using
`as.character()`, and then I used `pivot_longer()` to create the
variables `route_name` (route1, route2, etc).and `route_number`
(A/B/C/1/2/3, etc). There were many `NA` values in the `route_number`
after the data pivoting step, so these were omitted using `drop_na()`

Following the data tidying, there are 4270 rows and 10 columns. The
variables in this dataset include `line`, station-level variables such
as name, latitude and longitude, `route_name` and `route_number`,
`entry`, `vending`, `entrance_type` and `ada`, which indicates ADA
compliance.

  - The number of distinct stations defined by name and line is 465.
  - The number of stations that are ADA compliant is 84
  - The proportion of station entrances/ exits without vending that
    allow entrance is 0.311.
  - The number of distinct stations that serve the A train is 60
  - Of the stations that serve the A train, 17 are ADA compliant

## Problem 3

Read in and clean data pols-month data

``` r
pols_df = 
  read_csv("./data/pols-month.csv") %>% 
  separate(col = mon, into = c("year", "month", "day"), 
           sep = '-', 
           convert = TRUE) %>% 
  mutate(president = case_when(
           prez_gop == 1 ~ "gop",
           prez_dem == 1 ~ "dem")) %>% 
  select(-prez_gop, -prez_dem, -day)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
pols_df =
    left_join(pols_df, month_df, by = "month") %>% 
  select(year, month_name, everything(), -month)
```

Read in and clean snp dataset

``` r
snp_df = 
  read_csv("./data/snp.csv") %>% 
  separate(col = date, into = c("month", "day", "year"), 
           sep = '/', 
           convert = TRUE) %>%
  arrange(year, month) %>% 
  select(year, month, close)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
snp_df =
    left_join(snp_df, month_df, by = "month") %>% 
  select(year, month_name, everything(), -month)
```

Read in and clean unemployment data

``` r
unemploy_df = 
  read_csv("./data/unemployment.csv", 
           col_names = c("year", month.name), 
           skip = 1) %>%
  pivot_longer(cols = January:December,
               names_to = "month_name",
               values_to = "unemploy_rate")
```

    ## Parsed with column specification:
    ## cols(
    ##   year = col_double(),
    ##   January = col_double(),
    ##   February = col_double(),
    ##   March = col_double(),
    ##   April = col_double(),
    ##   May = col_double(),
    ##   June = col_double(),
    ##   July = col_double(),
    ##   August = col_double(),
    ##   September = col_double(),
    ##   October = col_double(),
    ##   November = col_double(),
    ##   December = col_double()
    ## )

Join pols, snp and unemployment datasets

``` r
# merge snp into pols
pols_snp <- inner_join(pols_df, snp_df, by = c("year", "month_name"))
#merge unemployment into pols_snp
pols_snp_unemploy <- inner_join(pols_snp, unemploy_df, by = c("year", "month_name"))
```

The `pols_df` dataset contains 822 rows and 9 columns of data related to
the number of national politicians and their party affiliations
(democratic or republican) by month and year. The `snp_df` contains 787
rows and 3 columns of data related to Standard & Poor’s stock market
index (S\&P). Lastly, `unemploy_df` contains 816 rows and 3 columns of
data regarding unemployment rates by year and month. The `pols_df`
spanned from 1947 to 2015, the `snp_df` from 1950 to 2015 and the
`unemploy_df` from 1948 to 2015

These datasets are the product of certain data wrangling procedures,
including using `separate()` to break up columns into `day`, `month` and
`year`. Additionally, for `unemploy_df`, `pivot_longer()` was used to
change the columns of January - December into one `month` column.
`month` was changed into `month_name` in all datasets.

After combining the datasets using `inner_join()`, the final dataset had
dimensions 786 rows by 11 columns. This resulting dataset has all
information available for the years 1950 to 2015. Key variables in the
dataset include the number of both democratic and republican senators,
governors, and representatives (`gov_gop`, `sen_gop`,
`rep_gop`,`gov_dem`, `sen_dem`,`rep_dem`) by month and year.
Additionally, there is information on whether the president was
democratic or republican in `president`. Lastly, the data contains
information on unemployment rate (`unemploy_rate`) and the closing s\&p
stock index (`close`) by month and year.
