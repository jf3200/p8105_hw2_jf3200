---
title: "Homework 2"
author: "Jessica Flynn"
output: github_document
---

```{r setup}
library(tidyverse)
library(readxl)
```

## Problem 1 

Read the Mr. Trashwheel dataset. 
```{r trashwheel_df}
trashwheel_df = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate( 
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read in precipitation data for 2018 and 2017
```{r precip_df_2017_2018}
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation", 
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation", 
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)

```


Combine annual precipitation
```{r combine_precip}
precip_df = 
  bind_rows(precip_2017, precip_2018)

``` 

Create month name 
```{r month_name}

month_df = 
  tibble( 
    month = 1:12, 
    month_name = month.name
  )

precip_df = 
  left_join(precip_df, month_df, by = "month")

```

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, MD. As trash enters the harbor, the trashwheel collects that trash and stores it in a dumpster. The dataset contains information on year, month and trash collected. Some specific trash types that are reported on include `cigarette_butts`, `chip_bags` and `plastic_bottles`, among others. There are also some metrics regarding the trash including `weight_tons` and `volume_cubic_yards`. There are a total of `r nrow(trashwheel_df)` rows in the final dataset and a total of `r ncol(trashwheel_df)` columns. The median number of sportsballs in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`.

Additional data sheets include precipitation data by month. Here, we looked specifically at the years 2017 and 2018. There are a total of `r nrow(precip_df)` rows in the data for these two years. The columns in the datset include `r colnames(precip_df)`. The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()`and the total in 2017 was  `r precip_df %>% filter(year == 2017) %>% pull(total) %>% sum()`.

## Problem 2 

Read in NYC Transit Data
```{r read_data_p2}
transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude,    starts_with("route"),entry, vending, entrance_type, ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE)) %>% 
  mutate_at(vars(route8:route11), as.character) %>% 
  pivot_longer(route1:route11, 
               names_to = "route_number", 
               values_to = "route_name") %>% 
  drop_na(route_name)

```


This dataset contains data related to the entrances and exits for each subway station in NYC. 

The cleaning steps thus far have included renaming the columns to be all snake-case and lowercase using `janitor::clean_names`. Next, I used `select()`to retain the columns of interest and converted `entry`from a character to a logical variable. These data were not in a tidy format. Having route1- route11 each as columns indicates to us that this may not be the tidiest way to present the data. In order to tidy these data, I first converted all of the route variables to be of the same class using `as.character()`, and then I used `pivot_longer` to create the variables `route_name` (A/B/C/1/2/3, etc) and `route_number`(route1, route2, etc). There were many `NA` values in the route name after the data tidying step, so these were omitted using `drop_na()`


Following the data tidying, there are `r nrow(transit_df)` rows and `r ncol(transit_df)` columns. The variables in this dataset include `line`, station-level variables such as name, latitude and longitude, `route_name` and `route_number`, `entry`, `vending`, `entrance_type` and `ada`, which indicates ADA compliance. 


Find distinct stations and answer questions
```{r distinct_stations}
#Make this a dataframe to call since we will use it to answer multiple questions

transit_df_distinct =  
  transit_df %>% 
    distinct(station_name,line, .keep_all = TRUE)
  
```

* The number of distinct stations defined by name and line is `r nrow(transit_df_distinct)`. 
* The number of stations that are ADA compliant is `r transit_df_distinct %>% filter(ada==TRUE) %>% nrow()`. 
* The proportion of station entrances/ exits without vending that allow entrance is `r round(transit_df %>% filter(vending=="NO", entry==TRUE) %>% nrow() / transit_df %>% filter(vending=="NO")%>% nrow(),2) `
* The number of distinct stations that serve the A train is `r transit_df_distinct %>% filter(route_name=="A") %>% nrow()`
* Of the stations that serve the A train `r transit_df_distinct %>% filter(route_name=="A", ada==TRUE) %>% nrow()` are ADA compliant

## Problem 3 


